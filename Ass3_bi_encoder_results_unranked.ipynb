{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJxbyzt-i8gf",
        "outputId": "1a5a10c8-fa23-477c-eeb0-a967d26ae145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install torch\n",
        "!pip install json\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Gas0BR4vlIHa"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_file(zip_path, extract_to):\n",
        "    # Ensure the extraction directory exists\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "\n",
        "    # Open the ZIP file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract all the contents into the specified directory\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "zip_path = './tuned_bi_directory/tuned_bi.zip'\n",
        "extract_to = 'tuned_bi_directory'\n",
        "unzip_file(zip_path, extract_to)"
      ],
      "metadata": {
        "id": "9cCuKOlhO62b"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1rJ1tQ2iNJwb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def format_json(file_path):\n",
        "    # Read the JSON data from the file\n",
        "    with open(file_path, 'r', encoding='utf-8') as infile:\n",
        "        data = json.load(infile)\n",
        "\n",
        "    # Write the formatted JSON data back to the same file\n",
        "    with open(file_path, 'w', encoding='utf-8') as outfile:\n",
        "        json.dump(data, outfile, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xRXkfETCNJwb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Takes Test qrel and then makes it into new json of just id -> query_text\n",
        "def match_and_update_text(qrels_path, topics_path, output_path):\n",
        "    with open(qrels_path, 'r', encoding='utf-8') as qrels_file:\n",
        "        qrels_data = json.load(qrels_file)\n",
        "\n",
        "    with open(topics_path, 'r', encoding='utf-8') as topics_file:\n",
        "        topics_data = json.load(topics_file)\n",
        "\n",
        "    topics_dict = {str(topic['Id']): topic['Title'] + \" \" + topic['Body'] + \" \" + \" \".join(topic['Tags']) for topic in topics_data}\n",
        "\n",
        "    updated_qrels_data = {}\n",
        "\n",
        "    for query_id in qrels_data.keys():\n",
        "        if query_id in topics_dict:\n",
        "            updated_qrels_data[query_id] = {'query_text': topics_dict[query_id]}\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "        json.dump(updated_qrels_data, output_file, indent=4)\n",
        "\n",
        "def prepare_all_topics_with_query_text(topics_path, output_path):\n",
        "    with open(topics_path, 'r', encoding='utf-8') as topics_file:\n",
        "        topics_data = json.load(topics_file)\n",
        "\n",
        "    # Prepare a dictionary with all topics, where each key is a topic ID\n",
        "    all_topics_data = {\n",
        "        str(topic['Id']): {'query_text': topic['Title'] + \" \" + topic['Body'] + \" \" + \" \".join(topic['Tags'])}\n",
        "        for topic in topics_data\n",
        "    }\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "        json.dump(all_topics_data, output_file, indent=4)\n",
        "\n",
        "\n",
        "# Qrels only for getting test data\n",
        "#qrels_path = 'updated_test_qrels.json'\n",
        "topics_path = 'topics_2.json'\n",
        "#output_path = 'updated_test_qrels.json'\n",
        "prepare_all_topics_with_query_text(topics_path, 'updated_topics.json')\n",
        "#match_and_update_text(prepare_top, topics_path, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6QoDr_EKlZZt"
      },
      "outputs": [],
      "source": [
        "# Define a function to load JSON files\n",
        "def load_json_file(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "# paths to the files\n",
        "topic_filepath = 'topics_2.json'\n",
        "answer_filepath = 'Answers.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Ym2FPSXQpd0i"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import bs4\n",
        "def clean_topics_text(item):\n",
        "\n",
        "    full_string = item['query_text']\n",
        "\n",
        "    full_string = bs4.BeautifulSoup(full_string, 'html.parser').text\n",
        "    full_string = re.sub(r'[^a-zA-Z\\s]', ' ', full_string)\n",
        "\n",
        "    return full_string\n",
        "\n",
        "def clean_answers_text(item):\n",
        "    full_string = bs4.BeautifulSoup(item['Text'], 'html.parser').text\n",
        "    full_string = re.sub(r'[^a-zA-Z\\s]', ' ', full_string)\n",
        "\n",
        "    return full_string\n",
        "\n",
        "topic_filepath = 'updated_topics.json'\n",
        "\n",
        "# Clean em' up\n",
        "topics = load_json_file(topic_filepath)\n",
        "answers = load_json_file(answer_filepath)\n",
        "\n",
        "\n",
        "cleaned_topics = [{'id': key, 'text': clean_topics_text(value)} for key,value in topics.items()]\n",
        "cleaned_answers = [{'id': answer['Id'], 'text': clean_answers_text(answer)} for answer in answers]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "iFkpkGeZlvoZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_path = 'tuned_bi_directory'\n",
        "\n",
        "bi_encoder = SentenceTransformer(model_path, local_files_only=False)\n",
        "topic_embeddings = bi_encoder.encode([topic['text'] for topic in cleaned_topics], convert_to_tensor=True)\n",
        "answer_embeddings = bi_encoder.encode([answer['text'] for answer in cleaned_answers], convert_to_tensor=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YNmEfyrpfyy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It-tXW-UpfkL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "b6COjJXWl0lE"
      },
      "outputs": [],
      "source": [
        "torch.save(topic_embeddings, 'topic_embeddings.pt')\n",
        "torch.save(answer_embeddings, 'answer_embeddings.pt')\n",
        "\n",
        "# Optionally, save the cosine similarity matrix\n",
        "cos_sim = util.cos_sim(topic_embeddings, answer_embeddings)\n",
        "torch.save(cos_sim, 'cos_sim.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxFH7IbCvtQk",
        "outputId": "28b034b9-7087-423d-947e-f2e66cfdfb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-35f5a9d3e1d6>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  topic_embeddings = torch.load('topic_embeddings.pt')\n",
            "<ipython-input-44-35f5a9d3e1d6>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  answer_embeddings = torch.load('answer_embeddings.pt')\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the saved embeddings\n",
        "topic_embeddings = torch.load('topic_embeddings.pt')\n",
        "answer_embeddings = torch.load('answer_embeddings.pt')\n",
        "\n",
        "# Step 2: Compute cosine similarity between topic embeddings and answer embeddings\n",
        "cos_sim = util.cos_sim(topic_embeddings, answer_embeddings)\n",
        "\n",
        "# Step 3: Get the top 100 results for each topic\n",
        "top_k = 100\n",
        "top_results = []\n",
        "\n",
        "# Iterate over topics and find top 100 answers for each\n",
        "for i, topic in enumerate(cleaned_topics):\n",
        "    topic_id = topic['id']\n",
        "    topic_text = topic['text']\n",
        "\n",
        "    # Compute cosine similarity between the topic and all answers\n",
        "    cos_sim = torch.nn.functional.cosine_similarity(topic_embeddings[i], answer_embeddings)\n",
        "\n",
        "    # Get top_k answers\n",
        "    top_k_values, top_k_indices = torch.topk(cos_sim, k=top_k)\n",
        "\n",
        "    # Prepare the results for this topic\n",
        "    topic_results = {\n",
        "        \"query_id\": topic_id,\n",
        "        \"query_text\": topic_text,\n",
        "        \"results\": [\n",
        "            {\"answer_id\": cleaned_answers[idx]['id'], \"answer_text\": cleaned_answers[idx]['text'], \"score\": val.item()}\n",
        "            for idx, val in zip(top_k_indices, top_k_values)\n",
        "        ]\n",
        "    }\n",
        "    top_results.append(topic_results)\n",
        "\n",
        "# Save the top results to a file\n",
        "with open('top_100_results.json', 'w') as f:\n",
        "    json.dump(top_results, f, indent=4)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}